# Bayesian Modeling Framework for Energy Efficiency Analysis
## Using PyMC 5 with JAX/GPU Acceleration and Statistical Rethinking Principles

**Date**: 2025-10-15
**Framework**: Jaynesian Bayesian approach with practical GPU-accelerated implementation
**Reference**: Statistical Rethinking (McElreath) - Python implementation via PyMC
**Backend**: PyMC 5 with JAX backend and NVIDIA GPU acceleration

---

## Executive Summary

This framework provides GPU-accelerated hierarchical Bayesian models for:
1. **Energy disaggregation** - inferring appliance-level consumption from total usage
2. **Program effectiveness** - predicting likelihood of benefiting from efficiency programs
3. **Messaging optimization** - modeling campaign effectiveness with demographic priors
4. **Property inference** - deriving household characteristics from available data

**Key Insights**:
- Your existing baseload models provide excellent priors for hierarchical energy disaggregation
- GPU acceleration with JAX provides **10-20x speedup** for hierarchical models
- Same PyMC model code works with CPU or GPU backends

---

## Hardware and Software Environment

### GPU Configuration
```
NVIDIA RTX A6000
- VRAM: 49,140 MiB (48GB)
- CUDA Version: 12.4
- Driver: 550.90.07
- Performance: Professional workstation GPU
- Expected speedup: 10-20x for hierarchical models vs CPU
```

**Why this GPU is excellent for Bayesian inference**:
- **Large VRAM (48GB)**: Can fit very large hierarchical models with thousands of parameters
- **High compute capability**: Professional GPU optimized for scientific computing
- **CUDA 12.4**: Latest CUDA toolkit with enhanced JAX support
- **Sufficient for all models**: Your models will use <15GB VRAM, leaving plenty of headroom

### Software Stack
```python
# Core dependencies (see Appendix B for full list)
pymc>=5.0.0              # Latest PyMC with JAX support
numpyro>=0.15.0          # JAX-based NUTS sampler
jax[cuda12]>=0.4.0       # JAX with CUDA 12 support
arviz>=0.14.0            # Diagnostics and visualization
```

### Performance Expectations

Based on research benchmarks with similar GPU (see `claudedocs/research_bayesian_performance_20251015.md`):

| Model Type | CPU (baseline) | JAX CPU | **JAX + RTX A6000** |
|------------|---------------|---------|---------------------|
| Energy disaggregation (1000 households) | 8-15 min | 3-6 min | **30-90 sec** (10-20x) |
| Messaging model (70 campaigns) | 12-20 min | 4-8 min | **1-3 min** (10-15x) |
| Program benefit (simpler) | 2-5 min | 1-2 min | **20-40 sec** (8-15x) |

**Note**: Speedup increases with model complexity and dataset size.

---

## Quick Start: Your First GPU-Accelerated Model

### Step 1: Verify GPU Setup (2 minutes)

```bash
# Check GPU is visible to system
nvidia-smi

# Verify JAX can see GPU
python -c "import jax; print(jax.devices())"
# Expected output: [CudaDevice(id=0)]
```

### Step 2: Simple Test Model (5 minutes)

```python
import pymc as pm
from pymc import sampling_jax
import numpy as np
import jax

# Verify GPU
print(f"JAX devices: {jax.devices()}")

# Simple hierarchical model to test GPU
np.random.seed(42)
n_groups = 50
n_per_group = 20
group_idx = np.repeat(np.arange(n_groups), n_per_group)
y = np.random.normal(loc=group_idx * 0.5, scale=1.0)

with pm.Model() as test_model:
    # Hyperpriors
    Œº_group = pm.Normal('Œº_group', 0, 10)
    œÉ_group = pm.HalfNormal('œÉ_group', 5)

    # Group-level parameters (non-centered)
    group_offset = pm.Normal('group_offset', 0, 1, shape=n_groups)
    group_means = pm.Deterministic('group_means',
                                    Œº_group + œÉ_group * group_offset)

    # Likelihood
    œÉ_obs = pm.HalfNormal('œÉ_obs', 2)
    y_obs = pm.Normal('y_obs', mu=group_means[group_idx],
                      sigma=œÉ_obs, observed=y)

# Sample with GPU
print("\nüöÄ Starting GPU-accelerated sampling...")
with test_model:
    trace = sampling_jax.sample_numpyro_nuts(
        1000,
        tune=500,
        chains=4
    )

print("\n‚úÖ GPU sampling successful!")
print(f"Sampled {len(trace.posterior.draw) * len(trace.posterior.chain)} draws")
```

**Expected output**:
```
JAX devices: [CudaDevice(id=0)]
üöÄ Starting GPU-accelerated sampling...
Compiling... (10-30 seconds first time)
Sampling... (should be fast after compilation)
‚úÖ GPU sampling successful!
Sampled 4000 draws
```

### Step 3: Compare CPU vs GPU (10 minutes)

```python
import time

# Benchmark CPU sampling
print("‚è±Ô∏è  CPU Sampling...")
with test_model:
    start = time.time()
    trace_cpu = pm.sample(1000, tune=500, chains=4)
    cpu_time = time.time() - start

# Benchmark GPU sampling
print("\n‚è±Ô∏è  GPU Sampling...")
with test_model:
    start = time.time()
    trace_gpu = sampling_jax.sample_numpyro_nuts(1000, tune=500, chains=4)
    gpu_time = time.time() - start

# Results
print(f"\nüìä Performance Comparison:")
print(f"CPU: {cpu_time:.1f} seconds")
print(f"GPU: {gpu_time:.1f} seconds")
print(f"Speedup: {cpu_time/gpu_time:.1f}x")
```

**Expected speedup**: 3-8x for this simple model, 10-20x for your hierarchical models.

### Step 4: Ready for Your Models

Once the test passes, you're ready to use the models in Part 1-3 below with GPU acceleration. Just replace:

```python
# OLD (CPU)
trace = pm.sample(2000, tune=1000)

# NEW (GPU)
trace = sampling_jax.sample_numpyro_nuts(2000, tune=1000, chains=4)
```

That's it! Your models will automatically use the GPU.

---

## Part 1: Energy Consumption Disaggregation Model

### Current State Analysis

Your existing models (`/lab/`) demonstrate sophisticated approaches:

**Strengths**:
- Well-defined causal DAGs for each energy source
- Temperature-dependent AC modeling with physical basis
- Categorical household size modeling with Hamilton County demographics
- Individual baseload models: lighting, stoves, hot water, clothes, freezers, devices

**Enhancement Opportunity**: Hierarchical structure for full disaggregation

### 1.1 Hierarchical Energy Disaggregation Model

#### Theoretical Framework

The total energy consumption `E_total` for household `h` in month `m` is:

```
E_total[h,m] = E_HVAC[h,m] + E_HW[h,m] + E_appliances[h,m] + E_baseload[h,m] + Œµ
```

Where each component follows a hierarchical structure capturing:
- **Household-level effects**: Size, age of home, number of occupants
- **Temporal effects**: Month, day of week, time of day
- **Environmental effects**: Weather (temp, humidity)
- **Demographic effects**: Income, age of residents

#### Statistical Model Structure

```python
# Hierarchical Bayesian Energy Disaggregation Model
# Following Statistical Rethinking principles

import pymc as pm
import numpy as np

with pm.Model() as energy_disagg_model:

    # === HYPERPRIORS (Population-level) ===

    # HVAC Component - Temperature Dependent
    # Based on your AC Power Consumption model
    Œº_hvac_temp_sensitivity = pm.Normal('Œº_hvac_temp_sens', 50, 20)  # kWh per degree-month
    œÉ_hvac_temp_sensitivity = pm.HalfNormal('œÉ_hvac_temp_sens', 10)

    Œº_hvac_baseline = pm.Normal('Œº_hvac_baseline', 200, 50)  # kWh baseline
    œÉ_hvac_baseline = pm.HalfNormal('œÉ_hvac_baseline', 30)

    # Hot Water Component - Occupancy Dependent
    # Based on your BaseLoadHotWater model
    Œº_hw_per_person = pm.Normal('Œº_hw_per_person', 80, 20)  # kWh per person
    œÉ_hw_per_person = pm.HalfNormal('œÉ_hw_per_person', 15)

    Œº_hw_baseline = pm.Normal('Œº_hw_baseline', 150, 30)
    œÉ_hw_baseline = pm.HalfNormal('œÉ_hw_baseline', 20)

    # Appliances - Your existing baseload models
    # Stoves, Clothes, Freezers, Devices, Lighting
    Œº_appliance_per_person = pm.Normal('Œº_app_per_person', 120, 30)
    œÉ_appliance_per_person = pm.HalfNormal('œÉ_app_per_person', 20)

    # Baseload - Always-on devices
    Œº_baseload = pm.Normal('Œº_baseload', 100, 20)
    œÉ_baseload = pm.HalfNormal('œÉ_baseload', 15)

    # === HOUSEHOLD-LEVEL PARAMETERS ===
    # n_households = number of households in dataset

    # Household-specific HVAC efficiency (non-centered parameterization)
    hvac_temp_sens_z = pm.Normal('hvac_temp_sens_z', 0, 1, shape=n_households)
    hvac_temp_sens = pm.Deterministic('hvac_temp_sens',
                                       Œº_hvac_temp_sensitivity +
                                       œÉ_hvac_temp_sensitivity * hvac_temp_sens_z)

    hvac_baseline_z = pm.Normal('hvac_baseline_z', 0, 1, shape=n_households)
    hvac_baseline = pm.Deterministic('hvac_baseline',
                                      Œº_hvac_baseline + œÉ_hvac_baseline * hvac_baseline_z)

    # Household-specific hot water usage
    hw_per_person_z = pm.Normal('hw_per_person_z', 0, 1, shape=n_households)
    hw_per_person = pm.Deterministic('hw_per_person',
                                      Œº_hw_per_person + œÉ_hw_per_person * hw_per_person_z)

    # Household-specific appliance usage
    app_per_person_z = pm.Normal('app_per_person_z', 0, 1, shape=n_households)
    app_per_person = pm.Deterministic('app_per_person',
                                       Œº_appliance_per_person +
                                       œÉ_appliance_per_person * app_per_person_z)

    # Household baseload
    baseload_z = pm.Normal('baseload_z', 0, 1, shape=n_households)
    baseload = pm.Deterministic('baseload',
                                 Œº_baseload + œÉ_baseload * baseload_z)

    # === COVARIATES ===
    # Data inputs (to be provided as theano.shared variables)
    # temp_diff = monthly average temp - setpoint (e.g., 72¬∞F)
    # n_occupants = number of people in household
    # home_age = age of home in years
    # home_sqft = square footage

    # === LIKELIHOOD COMPONENTS ===

    # HVAC energy (heating/cooling degree days approach)
    # temp_diff_data: array of shape (n_obs,) with temperature differentials
    # household_idx: array mapping each observation to household
    E_hvac = pm.Deterministic('E_hvac',
                              hvac_baseline[household_idx] +
                              hvac_temp_sens[household_idx] * temp_diff_data)

    # Hot water energy
    E_hw = pm.Deterministic('E_hw',
                            hw_per_person[household_idx] * n_occupants_data +
                            Œº_hw_baseline)

    # Appliance energy
    E_appliances = pm.Deterministic('E_appliances',
                                     app_per_person[household_idx] * n_occupants_data)

    # Baseload energy
    E_baseload_component = pm.Deterministic('E_baseload',
                                             baseload[household_idx])

    # === TOTAL ENERGY MODEL ===
    Œº_total = E_hvac + E_hw + E_appliances + E_baseload_component

    # Model uncertainty
    œÉ_obs = pm.HalfNormal('œÉ_obs', 50)

    # Likelihood
    E_total_obs = pm.Normal('E_total_obs', mu=Œº_total, sigma=œÉ_obs,
                             observed=energy_total_data)

    # === INFERENCE WITH JAX/GPU ===
    # GPU-accelerated sampling (automatically detects CUDA)
    # trace = pm.sampling_jax.sample_numpyro_nuts(
    #     2000,
    #     tune=1000,
    #     target_accept=0.95,
    #     chains=4
    # )
```

#### Key Features

1. **Non-centered Parameterization**: Improves sampling efficiency for hierarchical models
2. **Physical Constraints**: Temperature and occupancy relationships based on domain knowledge
3. **Partial Pooling**: Household-specific parameters drawn from population distributions
4. **Uncertainty Quantification**: Full posterior distributions for all components
5. **GPU Acceleration**: JAX backend with NumPyro sampler for 10-20x speedup

### 1.2 Enhanced Disaggregation with Additional Features

#### Extended Model with Demographic and Home Characteristics

```python
with pm.Model() as energy_disagg_extended:

    # === ADDITIONAL COVARIATES ===

    # Income effect on HVAC usage (higher income -> more usage)
    Œ≤_hvac_income = pm.Normal('Œ≤_hvac_income', 0, 10)

    # Home age effect on efficiency (older homes -> less efficient)
    Œ≤_hvac_age = pm.Normal('Œ≤_hvac_age', 0, 5)

    # Square footage effect on baseload
    Œ≤_baseload_sqft = pm.Normal('Œ≤_baseload_sqft', 0, 0.1)

    # Day of week effects (weekend vs weekday patterns)
    dow_effect = pm.Normal('dow_effect', 0, 20, shape=7)

    # Time of day effects (hourly if available)
    # hour_effect = pm.Normal('hour_effect', 0, 10, shape=24)

    # === MODIFIED LIKELIHOOD ===

    E_hvac_enhanced = (hvac_baseline[household_idx] +
                       hvac_temp_sens[household_idx] * temp_diff_data +
                       Œ≤_hvac_income * income_data +
                       Œ≤_hvac_age * home_age_data)

    E_baseload_enhanced = (baseload[household_idx] +
                           Œ≤_baseload_sqft * home_sqft_data)

    # Add day-of-week variation
    Œº_total = (E_hvac_enhanced + E_hw + E_appliances + E_baseload_enhanced +
               dow_effect[dow_data])

    œÉ_obs = pm.HalfNormal('œÉ_obs', 50)
    E_total_obs = pm.Normal('E_total_obs', mu=Œº_total, sigma=œÉ_obs,
                             observed=energy_total_data)
```

### 1.3 Integration with Existing Models

Your existing baseload models can serve as **informative priors**:

```python
# Extract posterior summaries from your existing models
# Example: from Baseloads Via Aggregation.ipynb

# Lighting model posteriors
lighting_energy_mean = 50  # kWh from your model
lighting_energy_sd = 15

# Use as priors in disaggregation model
with pm.Model() as integrated_model:
    # Lighting component with informative prior
    E_lighting = pm.Normal('E_lighting',
                           lighting_energy_mean,
                           lighting_energy_sd,
                           shape=n_households)

    # Similarly for other components...
```

---

## Part 2: Program Benefit Prediction Model

### 2.1 Likelihood of Benefiting from Energy Efficiency Programs

#### Theoretical Framework

We want to model `P(benefit | household_features)` where benefit could be:
- Binary: Will save > threshold (e.g., $200/year)
- Continuous: Expected savings amount
- Ordinal: Low/Medium/High benefit category

#### Logistic Regression Model with Hierarchical Structure

```python
with pm.Model() as program_benefit_model:

    # === FEATURES ===
    # From disaggregation model posteriors:
    # - Current HVAC efficiency (lower = more benefit potential)
    # - Hot water usage (higher = more benefit potential)
    # - Baseload level (some programs target this)
    # - Home age (older homes = more benefit)
    # - Income (affects ability to invest)

    # === PRIORS ===

    # Intercept
    Œ± = pm.Normal('Œ±', 0, 1)

    # Coefficients for continuous features
    Œ≤_hvac_inefficiency = pm.Normal('Œ≤_hvac_ineff', 0, 1)  # expect positive
    Œ≤_hw_usage = pm.Normal('Œ≤_hw_usage', 0, 0.5)
    Œ≤_home_age = pm.Normal('Œ≤_home_age', 0, 0.5)
    Œ≤_income = pm.Normal('Œ≤_income', 0, 0.3)  # could go either way
    Œ≤_sqft = pm.Normal('Œ≤_sqft', 0, 0.001)

    # Interaction: older homes with high usage
    Œ≤_interaction_age_usage = pm.Normal('Œ≤_interact', 0, 0.2)

    # === LINEAR MODEL ===

    # Standardize inputs for better sampling
    hvac_ineff_std = (hvac_inefficiency_data - hvac_inefficiency_data.mean()) / hvac_inefficiency_data.std()
    hw_usage_std = (hw_usage_data - hw_usage_data.mean()) / hw_usage_data.std()
    home_age_std = (home_age_data - home_age_data.mean()) / home_age_data.std()
    income_std = (income_data - income_data.mean()) / income_data.std()
    sqft_std = (sqft_data - sqft_data.mean()) / sqft_data.std()

    logit_p = (Œ± +
               Œ≤_hvac_inefficiency * hvac_ineff_std +
               Œ≤_hw_usage * hw_usage_std +
               Œ≤_home_age * home_age_std +
               Œ≤_income * income_std +
               Œ≤_sqft * sqft_std +
               Œ≤_interaction_age_usage * hvac_ineff_std * home_age_std)

    # === LIKELIHOOD ===

    # Binary outcome: high benefit (yes/no)
    p_benefit = pm.Deterministic('p_benefit', pm.math.sigmoid(logit_p))

    benefit_obs = pm.Bernoulli('benefit_obs', p=p_benefit,
                                observed=benefit_binary_data)

    # Alternative: Continuous savings amount
    # Œº_savings = pm.Deterministic('Œº_savings', pm.math.exp(logit_p) * 100)
    # œÉ_savings = pm.HalfNormal('œÉ_savings', 50)
    # savings_obs = pm.Normal('savings_obs', mu=Œº_savings, sigma=œÉ_savings,
    #                         observed=actual_savings_data)
```

### 2.2 Multi-Level Model by Program Type

Different programs target different inefficiencies:

```python
with pm.Model() as program_type_model:

    # Programs: HVAC upgrade, Insulation, Hot water, Appliances
    n_programs = 4

    # === HYPERPRIORS ===
    Œº_Œ± = pm.Normal('Œº_Œ±', 0, 1)
    œÉ_Œ± = pm.HalfNormal('œÉ_Œ±', 0.5)

    Œº_Œ≤_hvac = pm.Normal('Œº_Œ≤_hvac', 0, 0.5)
    œÉ_Œ≤_hvac = pm.HalfNormal('œÉ_Œ≤_hvac', 0.3)

    # ... similar for other features

    # === PROGRAM-SPECIFIC PARAMETERS ===
    Œ±_program = pm.Normal('Œ±_program', Œº_Œ±, œÉ_Œ±, shape=n_programs)
    Œ≤_hvac_program = pm.Normal('Œ≤_hvac_program', Œº_Œ≤_hvac, œÉ_Œ≤_hvac,
                                shape=n_programs)

    # === LIKELIHOOD ===
    # program_idx: which program is being considered for this household

    logit_p = (Œ±_program[program_idx] +
               Œ≤_hvac_program[program_idx] * hvac_ineff_std)

    p_benefit = pm.math.sigmoid(logit_p)
    benefit_obs = pm.Bernoulli('benefit_obs', p=p_benefit,
                                observed=benefit_data)
```

---

## Part 3: Messaging Effectiveness Model

### 3.1 Campaign Response Modeling

Your campaign data includes: `opened`, `clicked`, `applied`, demographics (`age`, `income`, `YearBuilt`), and campaign type.

#### Hierarchical Logistic Model for Conversion Funnel

```python
with pm.Model() as messaging_model:

    # === THREE-STAGE FUNNEL ===
    # Stage 1: P(opened | email sent)
    # Stage 2: P(clicked | opened)
    # Stage 3: P(applied | clicked)

    # === CAMPAIGN-LEVEL EFFECTS ===
    n_campaigns = n_unique_campaigns

    # Hyperpriors for campaign effects
    Œº_Œ±_open = pm.Normal('Œº_Œ±_open', 0, 1)
    œÉ_Œ±_open = pm.HalfNormal('œÉ_Œ±_open', 0.5)

    Œº_Œ±_click = pm.Normal('Œº_Œ±_click', 0, 1)
    œÉ_Œ±_click = pm.HalfNormal('œÉ_Œ±_click', 0.5)

    Œº_Œ±_apply = pm.Normal('Œº_Œ±_apply', 0, 1)
    œÉ_Œ±_apply = pm.HalfNormal('œÉ_Œ±_apply', 0.5)

    # Campaign-specific intercepts (partial pooling)
    Œ±_open = pm.Normal('Œ±_open', Œº_Œ±_open, œÉ_Œ±_open, shape=n_campaigns)
    Œ±_click = pm.Normal('Œ±_click', Œº_Œ±_click, œÉ_Œ±_click, shape=n_campaigns)
    Œ±_apply = pm.Normal('Œ±_apply', Œº_Œ±_apply, œÉ_Œ±_apply, shape=n_campaigns)

    # === DEMOGRAPHIC EFFECTS ===
    # (shared across campaigns but with varying magnitude)

    # Income effects
    Œ≤_income_open = pm.Normal('Œ≤_income_open', 0, 0.3)
    Œ≤_income_click = pm.Normal('Œ≤_income_click', 0, 0.3)
    Œ≤_income_apply = pm.Normal('Œ≤_income_apply', 0, 0.5)

    # Home age effects (older homes may be more interested)
    Œ≤_age_open = pm.Normal('Œ≤_age_open', 0, 0.01)
    Œ≤_age_click = pm.Normal('Œ≤_age_click', 0, 0.01)
    Œ≤_age_apply = pm.Normal('Œ≤_age_apply', 0, 0.02)

    # County effects (geographic variation)
    n_counties = n_unique_counties
    county_effect_open = pm.Normal('county_effect_open', 0, 0.3, shape=n_counties)
    county_effect_click = pm.Normal('county_effect_click', 0, 0.3, shape=n_counties)
    county_effect_apply = pm.Normal('county_effect_apply', 0, 0.5, shape=n_counties)

    # === SEASONAL/TEMPORAL EFFECTS ===
    # Month of campaign (summer vs winter messaging effectiveness)
    month_effect_open = pm.Normal('month_effect_open', 0, 0.2, shape=12)

    # === STANDARDIZE INPUTS ===
    income_std = (income_data - income_mean) / income_std_dev
    home_age_std = (home_age_data - home_age_mean) / home_age_std_dev

    # === STAGE 1: OPEN ===
    logit_open = (Œ±_open[campaign_idx] +
                  Œ≤_income_open * income_std +
                  Œ≤_age_open * home_age_std +
                  county_effect_open[county_idx] +
                  month_effect_open[month_idx])

    p_open = pm.Deterministic('p_open', pm.math.sigmoid(logit_open))
    opened_obs = pm.Bernoulli('opened_obs', p=p_open, observed=opened_data)

    # === STAGE 2: CLICK (conditional on opened) ===
    logit_click = (Œ±_click[campaign_idx] +
                   Œ≤_income_click * income_std +
                   Œ≤_age_click * home_age_std +
                   county_effect_click[county_idx])

    p_click = pm.Deterministic('p_click', pm.math.sigmoid(logit_click))

    # Only for those who opened
    clicked_obs = pm.Bernoulli('clicked_obs', p=p_click,
                                observed=clicked_data[opened_data == 1])

    # === STAGE 3: APPLY (conditional on clicked) ===
    logit_apply = (Œ±_apply[campaign_idx] +
                   Œ≤_income_apply * income_std +
                   Œ≤_age_apply * home_age_std +
                   county_effect_apply[county_idx])

    p_apply = pm.Deterministic('p_apply', pm.math.sigmoid(logit_apply))

    applied_obs = pm.Bernoulli('applied_obs', p=p_apply,
                                observed=applied_data[clicked_data == 1])
```

### 3.2 Campaign Type Analysis

Analyze which message framing is most effective:

```python
# Campaign types from your data:
# - Daily_Cost (cost framing)
# - Annual_Cost / Monthly_Savings (savings framing)
# - Summer_Surge / Crisis (urgency framing)
# - Your_Home_Selected (personalization)
# - Claude_Content (AI-generated content)
# - Improve (improvement framing)
# - Would_$_Per_Month (specific savings)

with pm.Model() as message_framing_model:

    # Message type categories
    message_types = ['cost', 'savings', 'urgency', 'personalization',
                     'improvement', 'specific_amount']
    n_msg_types = len(message_types)

    # Hierarchical structure: message type -> campaign -> individual

    # Message type effects
    Œº_msg_type = pm.Normal('Œº_msg_type', 0, 0.5, shape=n_msg_types)
    œÉ_msg_type = pm.HalfNormal('œÉ_msg_type', 0.3)

    # Campaign effects nested within message type
    Œ±_campaign = pm.Normal('Œ±_campaign',
                           Œº_msg_type[msg_type_idx],
                           œÉ_msg_type,
                           shape=n_campaigns)

    # Interaction: message type √ó income
    # (higher income may respond differently to cost vs savings framing)
    Œ≤_msg_income = pm.Normal('Œ≤_msg_income', 0, 0.2, shape=n_msg_types)

    # Interaction: message type √ó home age
    Œ≤_msg_age = pm.Normal('Œ≤_msg_age', 0, 0.01, shape=n_msg_types)

    # Likelihood
    logit_response = (Œ±_campaign[campaign_idx] +
                      Œ≤_msg_income[msg_type_idx] * income_std +
                      Œ≤_msg_age[msg_type_idx] * home_age_std)

    p_response = pm.math.sigmoid(logit_response)
    response_obs = pm.Bernoulli('response_obs', p=p_response,
                                  observed=response_data)
```

### 3.3 Personalized Messaging Recommendations

Use posterior predictions to optimize messaging:

```python
# After fitting messaging_model, generate predictions for new households

with messaging_model:
    # Posterior predictive for new household
    pm.set_data({
        'income_std': new_household_income_std,
        'home_age_std': new_household_age_std,
        'campaign_idx': candidate_campaigns,
        'county_idx': new_household_county,
        'month_idx': current_month
    })

    posterior_pred = pm.sample_posterior_predictive(trace,
                                                      var_names=['p_open', 'p_click', 'p_apply'])

# Rank campaigns by expected conversion for this household
expected_conversion = (posterior_pred['p_open'].mean(axis=0) *
                       posterior_pred['p_click'].mean(axis=0) *
                       posterior_pred['p_apply'].mean(axis=0))

best_campaign_idx = np.argmax(expected_conversion)
```

---

## Part 4: Inferrable Properties

### 4.1 What We Can Infer from Available Data

#### Direct Measurements
- Energy consumption (monthly bills)
- Temperature/weather data
- Campaign response behavior
- Demographics (where available): income, home age

#### Inferrable Properties (via Bayesian inference)

##### 4.1.1 HVAC System Efficiency

From energy consumption + temperature data:

```python
# Posterior distribution of household HVAC efficiency
# Lower temp_sens = more efficient system

with energy_disagg_model:
    trace = pm.sample()

# Extract efficiency estimates
hvac_efficiency_estimates = trace.posterior['hvac_temp_sens'].values

# Households with high temp_sens are candidates for HVAC upgrades
```

##### 4.1.2 Likely Occupancy / Household Size

From energy patterns:

```python
with pm.Model() as occupancy_inference:

    # Prior: Hamilton County demographics
    p_occupancy = np.array([0.242, 0.295, 0.159, 0.098, 0.047, 0.017, 0.006, 0.002])

    # True occupancy (latent variable)
    n_occupants = pm.Categorical('n_occupants', p=p_occupancy)

    # Occupancy affects hot water and appliance usage
    # Use your baseload models as likelihood
    E_hw_expected = hw_per_person * n_occupants + hw_baseline
    E_app_expected = app_per_person * n_occupants

    # Observed energy minus HVAC and baseload
    E_occupancy_dependent = pm.Normal('E_occ_dep',
                                       mu=E_hw_expected + E_app_expected,
                                       sigma=50,
                                       observed=observed_non_hvac_energy)

    trace = pm.sample()

# Posterior distribution over household sizes
occupancy_posterior = trace.posterior['n_occupants']
```

##### 4.1.3 Appliance Ownership

Infer presence of:
- Electric vs gas stove/oven
- Electric vs gas water heater
- Presence of additional freezers
- Number of large electronics

```python
with pm.Model() as appliance_inference:

    # Priors from population data
    p_electric_stove = 0.88  # from your notes
    p_electric_hw = 0.74
    p_has_freezer = 0.3  # estimate

    has_electric_stove = pm.Bernoulli('has_elec_stove', p=p_electric_stove)
    has_electric_hw = pm.Bernoulli('has_elec_hw', p=p_electric_hw)
    has_freezer = pm.Bernoulli('has_freezer', p=p_has_freezer)

    # These affect baseload energy
    E_baseload_expected = (has_electric_stove * stove_energy +
                           has_electric_hw * hw_energy +
                           has_freezer * freezer_energy +
                           standard_baseload)

    E_baseload_obs = pm.Normal('E_baseload_obs',
                                mu=E_baseload_expected,
                                sigma=30,
                                observed=observed_baseload)

    trace = pm.sample()
```

##### 4.1.4 Home Insulation Quality

From HVAC efficiency estimates + home age:

```python
# Insulation quality (not directly observed)
# Inferred from HVAC performance controlling for system age

with pm.Model() as insulation_model:

    # Latent insulation quality (0=poor, 1=excellent)
    insulation_quality = pm.Beta('insulation_quality', alpha=2, beta=2)

    # Affects HVAC efficiency
    # Better insulation -> lower HVAC temp sensitivity
    expected_hvac_sens = (hvac_sens_baseline * (1 - 0.3 * insulation_quality) +
                          home_age_effect * home_age)

    hvac_sens_obs = pm.Normal('hvac_sens_obs',
                               mu=expected_hvac_sens,
                               sigma=10,
                               observed=observed_hvac_sensitivity)
```

##### 4.1.5 Occupancy Schedule / Behavior Patterns

From time-of-day energy patterns (if available):

```python
# Infer:
# - Working from home vs commuting
# - Thermostat setback behavior
# - Time-of-use patterns

with pm.Model() as behavior_model:

    # Behavioral patterns
    # 0 = away during business hours, 1 = home all day
    occupancy_pattern = pm.Beta('occ_pattern', alpha=2, beta=2)

    # Thermostat setback discipline
    # 0 = no setback, 1 = strict setback
    setback_discipline = pm.Beta('setback_discipline', alpha=2, beta=2)

    # Affect daytime energy usage
    daytime_usage_factor = (occupancy_pattern * 1.5 +
                            (1 - setback_discipline) * 0.3)

    E_daytime = pm.Normal('E_daytime',
                          mu=baseline_usage * daytime_usage_factor,
                          sigma=20,
                          observed=observed_daytime_energy)
```

##### 4.1.6 Engagement Propensity

From campaign response behavior:

```python
# Latent "engagement score" predicting future response

with pm.Model() as engagement_model:

    # Latent engagement (continuously distributed)
    engagement_z = pm.Normal('engagement_z', 0, 1, shape=n_households)

    # Transforms to probability scale
    p_engage = pm.Deterministic('p_engage', pm.math.sigmoid(engagement_z))

    # Predicts multiple outcomes
    opened_obs = pm.Bernoulli('opened', p=p_engage * campaign_quality,
                               observed=opened_data)
    clicked_obs = pm.Bernoulli('clicked', p=p_engage**2 * content_quality,
                                 observed=clicked_data)
    applied_obs = pm.Bernoulli('applied', p=p_engage**3 * offer_quality,
                                observed=applied_data)

    trace = pm.sample()

# Posterior engagement scores predict future campaign success
engagement_scores = trace.posterior['p_engage'].mean(axis=(0,1))
```

### 4.2 Property Inference Summary Table

| Property | Data Sources | Confidence | Use Case |
|----------|--------------|------------|----------|
| **HVAC Efficiency** | Energy + Temperature | High | HVAC upgrade targeting |
| **Hot Water Type** | Baseload patterns | Medium | Water heater programs |
| **Household Size** | Energy + Demographics | Medium | Personalization |
| **Insulation Quality** | HVAC efficiency + Age | Medium | Insulation programs |
| **Stove/Oven Type** | Cooking energy patterns | Medium-Low | Appliance programs |
| **Occupancy Schedule** | Time-of-day patterns | High (if hourly data) | Behavioral programs |
| **Engagement Propensity** | Campaign responses | High | Messaging optimization |
| **Income (indirect)** | Energy usage + Home age | Low-Medium | Qualification screening |
| **Energy Literacy** | Response to messaging | Medium | Education programs |
| **Setback Behavior** | Temperature + Time patterns | Medium | Thermostat programs |

---

## Part 5: Implementation Workflow

### 5.1 Data Preparation Pipeline

```python
# File: prepare_data.py

import pandas as pd
import numpy as np
from pymongo import MongoClient

def load_energy_data():
    """Load energy consumption data from MongoDB"""
    client = MongoClient()
    db = client['HamiltonCounty']
    # Your existing data loading logic
    pass

def load_campaign_data():
    """Load messaging campaign data"""
    data_dir = '/home/frich/devel/EmpowerSaves/octopus/data/exports'
    campaigns = []
    for file in glob.glob(f"{data_dir}/campaign_*.csv"):
        df = pd.read_csv(file)
        campaigns.append(df)
    return pd.concat(campaigns, ignore_index=True)

def prepare_hierarchical_data(energy_df, demographic_df, weather_df):
    """
    Prepare data for hierarchical modeling

    Returns:
        dict with arrays/indices ready for PyMC
    """
    # Household indexing
    households = energy_df['household_id'].unique()
    n_households = len(households)
    household_lookup = {h: i for i, h in enumerate(households)}
    household_idx = np.array([household_lookup[h] for h in energy_df['household_id']])

    # Temporal data
    months = energy_df['month'].values
    years = energy_df['year'].values

    # Weather data (merge on month/year)
    energy_df = energy_df.merge(weather_df, on=['month', 'year'])
    temp_diff = energy_df['avg_temp'] - 72  # setpoint

    # Demographics
    energy_df = energy_df.merge(demographic_df, on='household_id')

    return {
        'n_households': n_households,
        'household_idx': household_idx,
        'energy_total': energy_df['kwh'].values,
        'temp_diff': temp_diff.values,
        'n_occupants': energy_df['n_occupants'].fillna(energy_df['n_occupants'].median()).values,
        'home_age': energy_df['year_built'].apply(lambda x: 2025 - x).values,
        'home_sqft': energy_df['sqft'].values,
        'income': energy_df['income'].fillna(energy_df['income'].median()).values,
    }
```

### 5.2 Model Training Pipeline (GPU-Accelerated)

```python
# File: train_models.py

import pymc as pm
from pymc import sampling_jax
import arviz as az
import pickle
import jax

def train_energy_disaggregation(data, use_gpu=True):
    """
    Train hierarchical energy disaggregation model with GPU acceleration

    Args:
        data: Prepared data dictionary
        use_gpu: Use JAX/GPU backend (default True)
    """

    # Verify GPU availability
    if use_gpu:
        print(f"JAX devices: {jax.devices()}")
        if 'gpu' in str(jax.devices()).lower():
            print("‚úÖ GPU detected and will be used for sampling")
        else:
            print("‚ö†Ô∏è  No GPU detected, falling back to JAX CPU")

    with pm.Model() as model:
        # [Insert model definition from Part 1]
        pass

    with model:
        if use_gpu:
            # GPU-accelerated sampling with NumPyro
            print("Starting GPU-accelerated sampling...")
            trace = sampling_jax.sample_numpyro_nuts(
                draws=2000,
                tune=1000,
                target_accept=0.95,
                chains=4,
                # NumPyro automatically uses GPU if available
            )
        else:
            # Fallback to standard CPU sampling
            print("Starting CPU sampling...")
            trace = pm.sample(
                2000,
                tune=1000,
                target_accept=0.95,
                return_inferencedata=True
            )

        # Diagnostics
        print("\n" + "="*60)
        print("Sampling Complete - Model Diagnostics")
        print("="*60)
        print(az.summary(trace,
                         var_names=['Œº_hvac_temp_sensitivity',
                                    'Œº_hw_per_person',
                                    'Œº_baseload'],
                         round_to=2))

        # Convergence checks
        rhat_max = az.rhat(trace).max().values
        print(f"\nConvergence check: max RÃÇ = {rhat_max:.4f}")
        assert rhat_max < 1.01, f"Poor convergence: max RÃÇ = {rhat_max:.4f}"
        print("‚úÖ Convergence check passed")

        # Save model and trace
        trace.to_netcdf('models/energy_disagg_trace.nc')
        print("\n‚úÖ Model saved to models/energy_disagg_trace.nc")

    return trace

def train_program_benefit_model(data, energy_trace):
    """Train program benefit prediction model"""

    # Extract household-level energy component estimates from energy_trace
    hvac_inefficiency = energy_trace.posterior['hvac_temp_sens'].mean(axis=(0,1))

    # [Continue with program benefit model from Part 2]
    pass

def train_messaging_model(campaign_data):
    """Train messaging effectiveness model"""
    # [Messaging model from Part 3]
    pass
```

### 5.3 Prediction and Recommendation Pipeline

```python
# File: predict.py

def predict_energy_components(household_features, trace):
    """
    Predict disaggregated energy for new household

    Returns:
        dict with posterior samples for each component
    """
    with model:  # reuse trained model
        pm.set_data(household_features)
        posterior_pred = pm.sample_posterior_predictive(
            trace,
            var_names=['E_hvac', 'E_hw', 'E_appliances', 'E_baseload']
        )

    return {
        'hvac': posterior_pred['E_hvac'],
        'hot_water': posterior_pred['E_hw'],
        'appliances': posterior_pred['E_appliances'],
        'baseload': posterior_pred['E_baseload']
    }

def recommend_programs(household_id, traces):
    """
    Recommend energy efficiency programs for household

    Returns:
        ranked list of programs with expected benefits
    """
    energy_trace = traces['energy']
    benefit_trace = traces['program_benefit']

    # Get household's energy components
    components = predict_energy_components(household_id, energy_trace)

    # Predict benefit probability for each program type
    programs = ['HVAC', 'Insulation', 'HotWater', 'Appliances']
    benefits = {}

    for program in programs:
        with benefit_trace.model:
            pm.set_data({'program_idx': program_idx[program]})
            pred = pm.sample_posterior_predictive(benefit_trace)
            benefits[program] = pred['p_benefit'].mean()

    # Rank programs
    ranked = sorted(benefits.items(), key=lambda x: x[1], reverse=True)

    return ranked

def optimize_messaging(household_features, trace):
    """
    Select optimal campaign message for household

    Returns:
        best_campaign, expected_conversion_rate
    """
    with messaging_model:
        pm.set_data(household_features)
        pred = pm.sample_posterior_predictive(trace)

        expected_conversion = (pred['p_open'].mean(axis=0) *
                               pred['p_click'].mean(axis=0) *
                               pred['p_apply'].mean(axis=0))

        best_idx = np.argmax(expected_conversion)
        best_campaign = campaign_types[best_idx]
        best_rate = expected_conversion[best_idx]

    return best_campaign, best_rate
```

---

## Part 6: Model Validation and Diagnostics

### 6.1 Posterior Predictive Checks

```python
# File: validate.py

import arviz as az
import matplotlib.pyplot as plt

def validate_energy_model(trace, observed_data):
    """
    Validate energy disaggregation model
    """
    # Posterior predictive check
    with model:
        ppc = pm.sample_posterior_predictive(trace)

    # Plot observed vs predicted
    fig, ax = plt.subplots(2, 2, figsize=(12, 10))

    # 1. Overall energy distribution
    az.plot_ppc(az.from_pymc3(posterior_predictive=ppc,
                               model=model),
                 ax=ax[0,0])
    ax[0,0].set_title("Posterior Predictive Check: Total Energy")

    # 2. Residuals vs fitted
    y_pred = ppc['E_total_obs'].mean(axis=0)
    residuals = observed_data - y_pred
    ax[0,1].scatter(y_pred, residuals, alpha=0.3)
    ax[0,1].axhline(0, color='red', linestyle='--')
    ax[0,1].set_xlabel("Predicted Energy (kWh)")
    ax[0,1].set_ylabel("Residuals")
    ax[0,1].set_title("Residual Plot")

    # 3. By household size
    for n in range(1, 9):
        mask = observed_data['n_occupants'] == n
        ax[1,0].hist(residuals[mask], alpha=0.5, label=f"N={n}")
    ax[1,0].set_title("Residuals by Household Size")
    ax[1,0].legend()

    # 4. By season
    for month in [1, 4, 7, 10]:  # Jan, Apr, Jul, Oct
        mask = observed_data['month'] == month
        ax[1,1].hist(residuals[mask], alpha=0.5, label=f"Month={month}")
    ax[1,1].set_title("Residuals by Season")
    ax[1,1].legend()

    plt.tight_layout()
    plt.savefig('validation/energy_model_diagnostics.png')

    # Numerical diagnostics
    print("Model Validation Metrics:")
    print(f"  RMSE: {np.sqrt(np.mean(residuals**2)):.2f} kWh")
    print(f"  MAE: {np.mean(np.abs(residuals)):.2f} kWh")
    print(f"  R¬≤: {1 - np.var(residuals) / np.var(observed_data):.3f}")

    # Check for systematic bias
    print(f"\nBias checks:")
    print(f"  Mean residual: {np.mean(residuals):.2f} (should be ~0)")
    print(f"  Residual skew: {pd.Series(residuals).skew():.2f} (should be ~0)")

def validate_component_estimates(trace, ground_truth=None):
    """
    Validate disaggregated components if ground truth available
    """
    if ground_truth is not None:
        # Compare to ground truth (e.g., from submetering)
        components = ['E_hvac', 'E_hw', 'E_appliances', 'E_baseload']

        for comp in components:
            predicted = trace.posterior[comp].mean(axis=(0,1))
            actual = ground_truth[comp]

            corr = np.corrcoef(predicted, actual)[0,1]
            rmse = np.sqrt(np.mean((predicted - actual)**2))

            print(f"{comp}:")
            print(f"  Correlation: {corr:.3f}")
            print(f"  RMSE: {rmse:.2f} kWh")

def cross_validate_models(data, n_folds=5):
    """
    K-fold cross-validation for all models
    """
    from sklearn.model_selection import KFold

    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)

    results = {'energy': [], 'program_benefit': [], 'messaging': []}

    for fold, (train_idx, test_idx) in enumerate(kf.split(data)):
        print(f"Fold {fold+1}/{n_folds}")

        train_data = data.iloc[train_idx]
        test_data = data.iloc[test_idx]

        # Train models
        energy_trace = train_energy_disaggregation(train_data)

        # Test predictions
        test_pred = predict_energy_components(test_data, energy_trace)
        test_rmse = np.sqrt(np.mean((test_pred - test_data['energy'])**2))

        results['energy'].append(test_rmse)

    print(f"\nCross-validation results:")
    print(f"  Energy RMSE: {np.mean(results['energy']):.2f} ¬± {np.std(results['energy']):.2f}")

    return results
```

### 6.2 Model Comparison

```python
def compare_models(traces):
    """
    Compare different model formulations using WAIC/LOO
    """
    # Compute information criteria
    waic_scores = {}
    loo_scores = {}

    for model_name, trace in traces.items():
        waic = az.waic(trace)
        loo = az.loo(trace)

        waic_scores[model_name] = waic.elpd_waic
        loo_scores[model_name] = loo.elpd_loo

        print(f"\n{model_name}:")
        print(f"  WAIC: {waic.elpd_waic:.2f} ¬± {waic.se:.2f}")
        print(f"  LOO: {loo.elpd_loo:.2f} ¬± {loo.se:.2f}")
        print(f"  p_loo: {loo.p_loo:.2f} (effective parameters)")

    # Compare models
    model_comparison = az.compare({name: trace for name, trace in traces.items()})
    print("\nModel Comparison:")
    print(model_comparison)

    return model_comparison
```

---

## Part 7: Deployment and Productionization

### 7.1 Model Serving

```python
# File: serve_models.py

from fastapi import FastAPI
from pydantic import BaseModel
import pickle
import numpy as np

app = FastAPI()

# Load trained models at startup
@app.on_event("startup")
def load_models():
    global energy_trace, program_trace, messaging_trace

    with open('models/energy_disagg_trace.pkl', 'rb') as f:
        energy_trace = pickle.load(f)

    with open('models/program_benefit_trace.pkl', 'rb') as f:
        program_trace = pickle.load(f)

    with open('models/messaging_trace.pkl', 'rb') as f:
        messaging_trace = pickle.load(f)

class HouseholdFeatures(BaseModel):
    household_id: str
    month: int
    avg_temp: float
    n_occupants: int
    home_age: int
    home_sqft: int
    income: float

@app.post("/predict/energy_components")
def predict_components(features: HouseholdFeatures):
    """
    Predict disaggregated energy components for household
    """
    predictions = predict_energy_components(
        features.dict(),
        energy_trace
    )

    # Return mean and 89% HDI
    return {
        'hvac': {
            'mean': float(predictions['hvac'].mean()),
            'hdi_lower': float(np.percentile(predictions['hvac'], 5.5)),
            'hdi_upper': float(np.percentile(predictions['hvac'], 94.5))
        },
        # ... similar for other components
    }

@app.post("/recommend/programs")
def recommend_efficiency_programs(features: HouseholdFeatures):
    """
    Recommend energy efficiency programs
    """
    recommendations = recommend_programs(
        features.household_id,
        {'energy': energy_trace, 'program_benefit': program_trace}
    )

    return {
        'programs': [
            {'name': prog, 'benefit_probability': float(prob)}
            for prog, prob in recommendations
        ]
    }

@app.post("/optimize/messaging")
def optimize_campaign_message(features: HouseholdFeatures):
    """
    Select optimal campaign message
    """
    campaign, conversion_rate = optimize_messaging(
        features.dict(),
        messaging_trace
    )

    return {
        'recommended_campaign': campaign,
        'expected_conversion_rate': float(conversion_rate)
    }
```

### 7.2 Monitoring and Retraining

```python
# File: monitor.py

import pandas as pd
from datetime import datetime, timedelta

class ModelMonitor:
    def __init__(self, trace_path, data_path):
        self.trace = self.load_trace(trace_path)
        self.data_path = data_path
        self.metrics_history = []

    def check_model_drift(self, new_data, threshold=0.15):
        """
        Check if model performance has degraded

        Returns:
            bool: True if retraining recommended
        """
        # Make predictions on new data
        predictions = self.predict(new_data)
        actuals = new_data['energy']

        # Calculate current RMSE
        current_rmse = np.sqrt(np.mean((predictions - actuals)**2))

        # Compare to training performance
        training_rmse = self.trace.attrs.get('training_rmse')

        drift = (current_rmse - training_rmse) / training_rmse

        self.metrics_history.append({
            'date': datetime.now(),
            'rmse': current_rmse,
            'drift': drift
        })

        if drift > threshold:
            print(f"‚ö†Ô∏è  Model drift detected: {drift:.1%} increase in RMSE")
            print(f"   Current RMSE: {current_rmse:.2f}")
            print(f"   Training RMSE: {training_rmse:.2f}")
            print(f"   Recommend retraining")
            return True

        return False

    def schedule_retraining(self, frequency='monthly'):
        """
        Automatically retrain models on schedule
        """
        if frequency == 'monthly':
            # Get data from last month
            start_date = datetime.now() - timedelta(days=30)
            new_data = self.load_recent_data(start_date)

            if len(new_data) > 1000:  # Sufficient data
                print(f"Retraining model with {len(new_data)} new samples")
                new_trace = train_energy_disaggregation(new_data)

                # Validate new model
                if self.validate_new_model(new_trace, new_data):
                    self.save_model(new_trace)
                    print("‚úÖ Model updated successfully")
                else:
                    print("‚ùå New model failed validation, keeping current model")
```

---

## Part 8: Advanced Topics

### 8.1 Time Series Extensions

For hourly or daily data:

```python
# Gaussian Process for temporal patterns

import pymc as pm

with pm.Model() as temporal_model:

    # Time indices
    time_idx = np.arange(len(energy_data))

    # GP hyperparameters
    Œ∑ = pm.HalfNormal('Œ∑', 10)  # amplitude
    ‚Ñì = pm.Gamma('‚Ñì', alpha=2, beta=0.5)  # length scale

    # Define covariance function
    cov_func = Œ∑**2 * pm.gp.cov.ExpQuad(1, ls=‚Ñì)

    # GP prior for temporal deviations
    gp = pm.gp.Latent(cov_func=cov_func)

    # Add GP term to energy model
    f_temporal = gp.prior('f_temporal', X=time_idx[:,None])

    Œº_total = E_hvac + E_hw + E_appliances + E_baseload + f_temporal

    œÉ_obs = pm.HalfNormal('œÉ_obs', 30)
    E_total_obs = pm.Normal('E_total_obs', mu=Œº_total, sigma=œÉ_obs,
                             observed=energy_data)
```

### 8.2 Causal Inference for Program Effects

Estimate *causal* impact of programs:

```python
# Difference-in-differences or synthetic control

with pm.Model() as causal_model:

    # Treatment indicator (program participation)
    treated = program_participation  # binary array

    # Time indicators
    post_treatment = (time_idx > treatment_start)  # binary

    # DID estimator
    Œ± = pm.Normal('Œ±', 0, 50)  # baseline
    Œ≤_treated = pm.Normal('Œ≤_treated', 0, 30)  # treatment effect
    Œ≤_time = pm.Normal('Œ≤_time', 0, 20)  # time trend
    œÑ = pm.Normal('œÑ', -50, 30)  # causal effect (expect negative = savings)

    Œº = Œ± + Œ≤_treated * treated + Œ≤_time * post_treatment + œÑ * (treated * post_treatment)

    œÉ = pm.HalfNormal('œÉ', 40)
    E_obs = pm.Normal('E_obs', mu=Œº, sigma=œÉ, observed=energy_data)

    # œÑ is the causal effect estimate
```

### 8.3 Bayesian Decision Theory

Optimize program enrollment decisions:

```python
# Expected value of enrolling household in program

def expected_utility(household_features, traces, costs, benefits):
    """
    Calculate expected utility of enrolling household

    Args:
        household_features: dict of household characteristics
        traces: dict of model traces
        costs: dict of program costs
        benefits: dict of potential benefits

    Returns:
        expected_utility: float (positive = enroll, negative = don't enroll)
    """
    # Predict benefit probability
    p_benefit = predict_program_benefit(household_features, traces)

    # Estimate savings amount
    current_usage = predict_energy_components(household_features, traces)
    potential_savings = estimate_savings_from_upgrades(current_usage)

    # Calculate expected utility
    program_cost = costs['program_cost']
    admin_cost = costs['admin_cost']

    expected_savings = potential_savings * p_benefit

    expected_utility = expected_savings - program_cost - admin_cost

    return expected_utility, p_benefit

# Decision rule
if expected_utility > 0:
    enroll_household()
else:
    defer_enrollment()
```

---

## Part 9: Integration with Statistical Rethinking Examples

### 9.1 Mapping to Statistical Rethinking Chapters

Your modeling aligns with these SR chapters:

- **Chapter 4**: Linear Models ‚Üí Your baseload models
- **Chapter 5**: Multiple Regression ‚Üí Energy disaggregation with covariates
- **Chapter 10**: Binary Outcomes ‚Üí Messaging effectiveness (logistic)
- **Chapter 11**: Ordered Categories ‚Üí Could use for benefit levels (low/med/high)
- **Chapter 13**: Multilevel Models ‚Üí Hierarchical household/campaign structure
- **Chapter 14**: Adventures in Covariance ‚Üí Time series with GPs

### 9.2 Using PyMC-Resources Examples

The PyMC version of Statistical Rethinking is at:
`https://github.com/pymc-devs/pymc-resources/tree/main/Rethinking`

Relevant notebooks for your use cases:

```python
# Notebook references for your models:

# Hierarchical models (like your household-level structure)
# See: Rethinking/Chp_13.ipynb

# Logistic regression (messaging effectiveness)
# See: Rethinking/Chp_10.ipynb

# Multiple regression with interactions
# See: Rethinking/Chp_07.ipynb and Chp_08.ipynb

# Model comparison
# See: Rethinking/Chp_09.ipynb
```

### 9.3 Practical Tips from Statistical Rethinking

1. **Always use non-centered parameterization** for hierarchical models (you'll see this in Ch 13)
2. **Standardize predictors** for better sampling and interpretability
3. **Use prior predictive simulations** to check if priors make sense
4. **Check posterior predictive distributions** against observed data
5. **Use information criteria** (WAIC/LOO) for model comparison, not p-values

---

## Part 10: Next Steps and Roadmap

### Immediate Implementation (Week 1-2)

1. **Data pipeline setup**
   - Consolidate energy data from MongoDB
   - Merge campaign data from CSV exports
   - Create cleaned dataset with all covariates

2. **Baseline model training**
   - Start with simplified energy disaggregation (HVAC + residual)
   - Train basic logistic model for program benefit
   - Validate against held-out data

3. **Initial predictions**
   - Generate household-level energy component estimates
   - Identify top candidates for HVAC upgrades
   - Test messaging optimization on recent campaigns

### Short-term Development (Month 1-2)

1. **Full hierarchical models**
   - Implement complete energy disaggregation with all components
   - Add demographic and temporal effects
   - Validate against your existing baseload models

2. **Messaging optimization**
   - Train full conversion funnel model
   - Analyze message type effectiveness
   - Generate personalized campaign recommendations

3. **Property inference**
   - Infer household sizes and appliance ownership
   - Estimate HVAC and insulation quality
   - Validate against known ground truth where available

### Medium-term Goals (Month 3-6)

1. **Causal inference**
   - Analyze actual program effects using DID or synthetic control
   - Quantify ROI of different program types
   - Optimize program portfolio

2. **Advanced temporal models**
   - Incorporate time series patterns with GPs
   - Model seasonal variations explicitly
   - Predict future energy usage

3. **Decision support system**
   - Build API for real-time predictions
   - Create dashboard for program administrators
   - Automate program recommendations and messaging

### Long-term Vision (6+ months)

1. **Continuous learning**
   - Implement online learning for model updates
   - Monitor model drift and trigger retraining
   - Incorporate feedback from program outcomes

2. **Expanded scope**
   - Include more detailed sub-metering where available
   - Integrate with smart thermostat data
   - Expand to commercial buildings

3. **Policy analysis**
   - Simulate impact of different policy interventions
   - Optimize subsidy levels and targeting
   - Estimate population-level energy savings

---

## Appendix A: Code Repository Structure

```
/home/frich/devel/EmpowerSaves/
‚îú‚îÄ‚îÄ lab/                           # Your existing exploration notebooks
‚îú‚îÄ‚îÄ octopus/
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ exports/               # Campaign data
‚îÇ   ‚îú‚îÄ‚îÄ models/                    # NEW: Bayesian model implementations
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ energy_disaggregation.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ program_benefit.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ messaging_effectiveness.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ property_inference.py
‚îÇ   ‚îú‚îÄ‚îÄ pipelines/                 # NEW: Data and training pipelines
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ prepare_data.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train_models.py
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ validate.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ predict.py
‚îÇ   ‚îú‚îÄ‚îÄ api/                       # NEW: Model serving
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ serve_models.py
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitor.py
‚îÇ   ‚îú‚îÄ‚îÄ notebooks/                 # NEW: Analysis notebooks
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 01_energy_disaggregation.ipynb
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 02_program_targeting.ipynb
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 03_messaging_optimization.ipynb
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 04_property_inference.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ tests/                     # NEW: Unit tests
‚îÇ   ‚îú‚îÄ‚îÄ claudedocs/                # Claude-generated documentation
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bayesian_modeling_framework.md  # This document
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt           # Dependencies
‚îî‚îÄ‚îÄ empower_analytics/
    ‚îî‚îÄ‚îÄ src/                       # Your existing analytics code
```

## Appendix B: Dependencies

```txt
# requirements.txt

# Core Bayesian modeling with GPU acceleration
pymc>=5.0.0                    # Latest PyMC with JAX support
arviz>=0.14.0                  # Diagnostics and visualization
pytensor>=2.18.0               # PyMC computational backend

# JAX ecosystem (GPU acceleration)
jax[cuda12]>=0.4.20            # JAX with CUDA 12 support for NVIDIA GPU
jaxlib>=0.4.20                 # JAX linear algebra backend
numpyro>=0.15.0                # JAX-based NUTS sampler
blackjax>=1.0.0                # Alternative JAX samplers (optional)

# Data manipulation
pandas>=1.5.0
numpy>=1.23.0

# Database
pymongo>=4.0.0
psycopg2-binary>=2.9.0

# Visualization
matplotlib>=3.6.0
seaborn>=0.12.0

# Causal inference
causalgraphicalmodels>=0.0.4
daft>=0.1.0  # for drawing DAGs

# Model serving
fastapi>=0.95.0
uvicorn>=0.21.0
pydantic>=1.10.0

# Utilities
scikit-learn>=1.2.0
scipy>=1.10.0
```

### Installation Instructions

**For NVIDIA RTX A6000 with CUDA 12.4:**

```bash
# Create virtual environment
python -m venv venv_bayesian
source venv_bayesian/bin/activate  # On Linux/Mac
# venv_bayesian\Scripts\activate  # On Windows

# Install JAX with CUDA 12 support
pip install --upgrade pip
pip install jax[cuda12] jaxlib -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html

# Install NumPyro and PyMC
pip install numpyro pymc>=5.0.0 arviz

# Install remaining dependencies
pip install -r requirements.txt

# Verify GPU detection
python -c "import jax; print('JAX devices:', jax.devices())"
# Should show: [CudaDevice(id=0)]
```

**Alternative: If using pip from requirements.txt directly:**

```bash
# Install all at once
pip install -r requirements.txt

# Verify installation
python -c "import pymc; import jax; print(f'PyMC {pymc.__version__}'); print(f'JAX devices: {jax.devices()}')"
```

## Appendix C: References

### Books
- **Statistical Rethinking** (McElreath) - Main theoretical foundation
- **Bayesian Data Analysis** (Gelman et al.) - Advanced techniques
- **Probabilistic Programming & Bayesian Methods** (Davidson-Pilon) - Practical PyMC guide

### Papers
- Energy disaggregation: NILM (Non-Intrusive Load Monitoring) literature
- Messaging effectiveness: Behavioral economics and nudge theory
- Causal inference: Rubin causal model, potential outcomes framework

### Code Resources
- PyMC Resources: https://github.com/pymc-devs/pymc-resources
- Statistical Rethinking in Python: https://github.com/pymc-devs/pymc-resources/tree/main/Rethinking
- PyMC Examples: https://www.pymc.io/projects/examples/en/latest/

---

## Summary

This framework provides a comprehensive **GPU-accelerated** Bayesian approach to:

1. **Disaggregate energy consumption** into HVAC, hot water, appliances, and baseload
2. **Predict program benefits** for individual households
3. **Optimize messaging campaigns** using hierarchical response models
4. **Infer household properties** from limited observational data

**Key principles**:
- Hierarchical models for partial pooling across households
- Informative priors from your existing domain knowledge
- Full uncertainty quantification via posterior distributions
- Causal thinking guided by DAGs
- Practical implementation with PyMC 5 + JAX following Statistical Rethinking
- **GPU acceleration with NVIDIA RTX A6000 for 10-20x speedup**

**Implementation advantages**:
- **Same model code** works on CPU or GPU (just change sampler)
- **Massive speedup**: 8-15 min ‚Üí 30-90 sec for energy disaggregation
- **Rapid iteration**: Run 10x more experiments in same time
- **Production-ready**: 48GB VRAM handles all model sizes with room to spare

**Next action**: Review this framework and prioritize which models to implement first based on your immediate business needs. With GPU acceleration, you can rapidly prototype and validate all three models in a single day of development.
